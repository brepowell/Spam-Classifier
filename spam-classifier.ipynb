{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breanna Powell and Melody Behdarvandian\n",
    "# CSS 576\n",
    "# Assignment 3\n",
    "\n",
    "# IDE: Visual Studio Code \n",
    "# Follow these steps if you have not used Jupyter Notebooks in VS Code before:\n",
    "# https://code.visualstudio.com/docs/languages/python\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "#                    FOLLOW THESE STEPS TO INSTALL TENSORFLOW in VS CODE\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Open Anaconda Navigator \n",
    "# Launch VS Code through Anaconda Navigator\n",
    "# Terminal > New Terminal\n",
    "#\n",
    "# https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/\n",
    "# 1) Use the commands:\n",
    "#    $ conda create -n tf tensorflow\n",
    "#    $ conda activate tf\n",
    "#\n",
    "# https://code.visualstudio.com/docs/datascience/jupyter-notebooks#_create-or-open-a-jupyter-notebook\n",
    "# 2) In the upper right hand corner, switch the kernel from \"base\" over to \"tf(Python 3.10.9)\"\n",
    "#\n",
    "# 3) Close this document and reopen it from Anaconda Navigator, but instead of \"base\" select \"tf\" from the dropdown menu\n",
    "# 4) Install the following:\n",
    "#    $ conda install pandas matplotlib scikit-learn seaborn\n",
    "#    $ conda install -c conda-forge tensorflow keras\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "emailData = pd.read_csv('emails.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emailData.shape # Check the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   label       5572 non-null   object\n",
      " 1   email       5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check to see if there are missing values (NaN or null)\n",
    "emailData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                              email Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emailData.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING TECHNIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              email Unnamed: 2  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      0                      Ok lar... Joking wif u oni...        NaN   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      0  U dun say so early hor... U c already then say...        NaN   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace labels with 0 for ham and 1 for spam\n",
    "emailData[\"label\"] = (emailData[\"label\"] == \"spam\").astype(int)\n",
    "\n",
    "# Check to make sure it worked\n",
    "emailData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (x) from the labels (y)\n",
    "x = emailData['email']\n",
    "y = emailData[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8673)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply a count vectorizer to the training data to convert from text to token counts\n",
    "# Count vectorizer -- will it ensure the testing data has no impact on the training data's normalization?\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer() # LOOK FOR OTHER PARAMETERS TO USE\n",
    "features = cv.fit_transform(x)\n",
    "features.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8673 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 73917 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputing missing values with the most frequent value\n",
    "# https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputedEmails = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputedEmails.fit_transform(features)\n",
    "imputedEmails.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features is now in csr format (rather than a series or dataframe)\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
    "type(features)\n",
    "x = pd.DataFrame(features.toarray()) # convert it to an dataframe instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to make sure that there are no NaN's after using the imputer\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html\n",
    "x.isna().sum().sum()\n",
    "\n",
    "# Should print 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 8673)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4457"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4457"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8673,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "num_classes = 1 # - spam or ham\n",
    "train_shape = x_train.shape\n",
    "filter_size = 32 # Should be a power of 2\n",
    "\n",
    "b = train_shape[1]\n",
    "input_shape = (b,)\n",
    "\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# https://keras.io/api/models/sequential/\n",
    "\n",
    "\n",
    "# Activation function options:\n",
    "# - relu\n",
    "# - sigmoid - good for last layer of binary classification\n",
    "# - elu - need to research this one\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_shape= input_shape, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid')) # Always use a sigmoid function for final layer when performing binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "# https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/\n",
    "# Monitor options:\n",
    "#  - loss\n",
    "#  - accuracy\n",
    "#  - val_loss\n",
    "#  - val_binary_crossentropy\n",
    "# Mode options:\n",
    "#  - min\n",
    "\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='auc', patience=3) # stops if the accuracy gets high\n",
    "# callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3) # monitors loss if the performance goes down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 69392     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,433\n",
      "Trainable params: 69,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #This tells us what was in this network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brely\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - ETA: 0s - loss: 0.0929 - auc_1: 0.9890WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 7s 40ms/step - loss: 0.0929 - auc_1: 0.9890\n",
      "Epoch 2/50\n",
      "135/140 [===========================>..] - ETA: 0s - loss: 0.0849 - auc_1: 0.9891WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 3s 23ms/step - loss: 0.0847 - auc_1: 0.9892\n",
      "Epoch 3/50\n",
      "136/140 [============================>.] - ETA: 0s - loss: 0.0784 - auc_1: 0.9897WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0780 - auc_1: 0.9898\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0722 - auc_1: 0.9912WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 3s 19ms/step - loss: 0.0722 - auc_1: 0.9912\n",
      "Epoch 5/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0675 - auc_1: 0.9901WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 32ms/step - loss: 0.0674 - auc_1: 0.9901\n",
      "Epoch 6/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0632 - auc_1: 0.9915WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 33ms/step - loss: 0.0631 - auc_1: 0.9915\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0594 - auc_1: 0.9915WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 28ms/step - loss: 0.0594 - auc_1: 0.9915\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0559 - auc_1: 0.9927WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.0559 - auc_1: 0.9927\n",
      "Epoch 9/50\n",
      "138/140 [============================>.] - ETA: 0s - loss: 0.0530 - auc_1: 0.9930WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 28ms/step - loss: 0.0529 - auc_1: 0.9930\n",
      "Epoch 10/50\n",
      "137/140 [============================>.] - ETA: 0s - loss: 0.0491 - auc_1: 0.9944WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0501 - auc_1: 0.9942\n",
      "Epoch 11/50\n",
      "137/140 [============================>.] - ETA: 0s - loss: 0.0472 - auc_1: 0.9946WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0475 - auc_1: 0.9945\n",
      "Epoch 12/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0452 - auc_1: 0.9956WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 31ms/step - loss: 0.0451 - auc_1: 0.9957\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0430 - auc_1: 0.9960WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 32ms/step - loss: 0.0430 - auc_1: 0.9960\n",
      "Epoch 14/50\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 0.0413 - auc_1: 0.9962WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 3s 22ms/step - loss: 0.0409 - auc_1: 0.9965\n",
      "Epoch 15/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0391 - auc_1: 0.9967WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 28ms/step - loss: 0.0390 - auc_1: 0.9967\n",
      "Epoch 16/50\n",
      "136/140 [============================>.] - ETA: 0s - loss: 0.0371 - auc_1: 0.9970WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0372 - auc_1: 0.9970\n",
      "Epoch 17/50\n",
      "137/140 [============================>.] - ETA: 0s - loss: 0.0357 - auc_1: 0.9972WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0355 - auc_1: 0.9972\n",
      "Epoch 18/50\n",
      "132/140 [===========================>..] - ETA: 0s - loss: 0.0339 - auc_1: 0.9973WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0340 - auc_1: 0.9974\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0325 - auc_1: 0.9976WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 0.0325 - auc_1: 0.9976\n",
      "Epoch 20/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0310 - auc_1: 0.9979WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 3s 21ms/step - loss: 0.0310 - auc_1: 0.9979\n",
      "Epoch 21/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0297 - auc_1: 0.9980WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.0297 - auc_1: 0.9980\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0284 - auc_1: 0.9981WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 6s 40ms/step - loss: 0.0284 - auc_1: 0.9981\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0273 - auc_1: 0.9982WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0273 - auc_1: 0.9982\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0262 - auc_1: 0.9982WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.0262 - auc_1: 0.9982\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0251 - auc_1: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 38ms/step - loss: 0.0251 - auc_1: 0.9983\n",
      "Epoch 26/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0241 - auc_1: 0.9984WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 31ms/step - loss: 0.0240 - auc_1: 0.9984\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0231 - auc_1: 0.9984WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.0231 - auc_1: 0.9984\n",
      "Epoch 28/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0221 - auc_1: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0221 - auc_1: 0.9985\n",
      "Epoch 29/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0212 - auc_1: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 6s 41ms/step - loss: 0.0212 - auc_1: 0.9985\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0204 - auc_1: 0.9993WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.0204 - auc_1: 0.9993\n",
      "Epoch 31/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0195 - auc_1: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 0.0196 - auc_1: 0.9994\n",
      "Epoch 32/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0188 - auc_1: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0188 - auc_1: 0.9994\n",
      "Epoch 33/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0181 - auc_1: 0.9995WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 38ms/step - loss: 0.0181 - auc_1: 0.9995\n",
      "Epoch 34/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0174 - auc_1: 0.9996WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.0174 - auc_1: 0.9996\n",
      "Epoch 35/50\n",
      "135/140 [===========================>..] - ETA: 0s - loss: 0.0171 - auc_1: 0.9996WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 3s 22ms/step - loss: 0.0168 - auc_1: 0.9996\n",
      "Epoch 36/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0161 - auc_1: 0.9996WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.0161 - auc_1: 0.9996\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0155 - auc_1: 0.9997WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.0155 - auc_1: 0.9997\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0149 - auc_1: 0.9997WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.0149 - auc_1: 0.9997\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0144 - auc_1: 0.9997WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0144 - auc_1: 0.9997\n",
      "Epoch 40/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0139 - auc_1: 0.9997WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0139 - auc_1: 0.9997\n",
      "Epoch 41/50\n",
      "135/140 [===========================>..] - ETA: 0s - loss: 0.0134 - auc_1: 0.9997WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 3s 20ms/step - loss: 0.0134 - auc_1: 0.9997\n",
      "Epoch 42/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0130 - auc_1: 0.9997WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 2s 11ms/step - loss: 0.0129 - auc_1: 0.9997\n",
      "Epoch 43/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0125 - auc_1: 0.9997WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 3s 21ms/step - loss: 0.0125 - auc_1: 0.9997\n",
      "Epoch 44/50\n",
      "138/140 [============================>.] - ETA: 0s - loss: 0.0120 - auc_1: 0.9997WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 6s 41ms/step - loss: 0.0121 - auc_1: 0.9997\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0117 - auc_1: 0.9990WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 28ms/step - loss: 0.0117 - auc_1: 0.9990\n",
      "Epoch 46/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0113 - auc_1: 0.9989WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 27ms/step - loss: 0.0113 - auc_1: 0.9989\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0110 - auc_1: 0.9998WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 31ms/step - loss: 0.0110 - auc_1: 0.9998\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0107 - auc_1: 0.9998WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0107 - auc_1: 0.9998\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0103 - auc_1: 0.9998WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 4s 31ms/step - loss: 0.0103 - auc_1: 0.9998\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0100 - auc_1: 0.9998WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_1\n",
      "140/140 [==============================] - 6s 41ms/step - loss: 0.0100 - auc_1: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121e0eb0670>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://keras.io/api/metrics/classification_metrics/#precision-class\n",
    "# Optimizer options:\n",
    "# - sgd (stochastic gradient descent)\n",
    "# - adam?\n",
    "# - rmsprop?\n",
    "\n",
    "# https://keras.io/api/losses/\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses  <---------- TO DO: LOOK THROUGH THESE\n",
    "# Loss parameter options: \n",
    "# - binary_crossentropy # https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class\n",
    "# - mse \n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
    "# metrics can be a list, like this: metrics=[\"mae\", \"acc\"]\n",
    "# Metrics parameter options:\n",
    "# - accuracy\n",
    "# - precision\n",
    "# - recall\n",
    "\n",
    "# TO DO: decide if we should use any optimizers (rmsprop, adam, sgd, adagrad, adadelta)\n",
    "\n",
    "from keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "model.compile(optimizer='sgd',\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.AUC(from_logits=True)])\n",
    "model.fit(x = x_train, y = y_train, epochs=epochs, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brely\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.051088668406009674\n",
      "Test accuracy: 0.9841631054878235\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "\n",
    "# I wonder about this metric? -- it uses spam and ham in the example!\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/spam-detection-in-emails-de0398ea3b48\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# cf_matrix =confusion_matrix(y_test,y_predict)\n",
    "\n",
    "# ax= plt.subplot()\n",
    "# #annot=True to annotate cells\n",
    "# sns.heatmap(cf_matrix, annot=True, ax = ax,cmap='Blues',fmt='');\n",
    "# # labels, title and ticks\n",
    "# ax.set_xlabel('Predicted labels');\n",
    "# ax.set_ylabel('True labels');\n",
    "# ax.set_title('Confusion Matrix');\n",
    "# ax.xaxis.set_ticklabels(['Not Spam', 'Spam']); ax.yaxis.set_ticklabels(['Not Spam', 'Spam']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74e93aff87d6e2cf52d5a8e93524dd20fc702e53e0159cbe929e143a46520959"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
